{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベース・モデルは LightGBM を用いて，モデル選択は層化K分割交差検証 (K=5) を用いたプログラムに変更した<br>\n",
    "追加１・使用する特徴量を相関係数から選択した。<br>\n",
    "追加２・学習データを分け、モデルを評価できるようにした"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クロスバリデーションの比較\n",
    "・k 分割交差検証 ( StratifiedKFold ) \n",
    "RepeatedStratifiedKFold\n",
    "GroupKFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in g:\\data_analysis_training\\.conda\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in g:\\data_analysis_training\\.conda\\lib\\site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: numpy in g:\\data_analysis_training\\.conda\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in g:\\data_analysis_training\\.conda\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in g:\\data_analysis_training\\.conda\\lib\\site-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in g:\\data_analysis_training\\.conda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in g:\\data_analysis_training\\.conda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "g:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8875\n",
      "Validation Accuracy:  0.546875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    " # データの読み込み\n",
    "train = pd.read_csv(\"./original/train.csv\")\n",
    "test = pd.read_csv(\"./original/test.csv\")\n",
    "\n",
    " # 特徴量と目的変数に分ける\n",
    "X_train = train.drop(\"price_range\", axis=1)\n",
    "y_train = train[\"price_range\"]\n",
    "X_test = test.copy()\n",
    "\n",
    " # train_test_splitを使用して学習データを分割する\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    " # 特徴量のスケーリング\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train_)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    " # ハイパーパラメータの設定\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'metric': 'multi_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_jobs': -1,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    " # モデルの作成と学習\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "oof = np.zeros((len(X_train_), 4))\n",
    "y_pred = np.zeros((len(X_test), 4))\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(X_train_, y_train_)):\n",
    "    X_tr = X_train_[train_index]\n",
    "    y_tr = y_train_.iloc[train_index]\n",
    "    X_val = X_train_[valid_index]\n",
    "    y_val = y_train_.iloc[valid_index]\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    oof[valid_index] = model.predict_proba(X_val)\n",
    "    y_pred += model.predict_proba(X_test) / n_splits\n",
    "    \n",
    " # モデルの評価\n",
    "y_train_pred = model.predict(X_train_)\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Training Accuracy: \", accuracy_score(y_train_, y_train_pred))\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    " # 予測結果の出力\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"price_range\": y_pred})\n",
    "output.to_csv(\"./submission/submission_lgbm_v9_skf.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1978</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1982</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  price_range\n",
       "0        1            1\n",
       "1        2            0\n",
       "2        6            3\n",
       "3       10            1\n",
       "4       12            1\n",
       "..     ...          ...\n",
       "795   1978            3\n",
       "796   1980            1\n",
       "797   1982            3\n",
       "798   1988            2\n",
       "799   1998            2\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [960, 960, 1200]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m oof \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(X_train_), \u001b[39m4\u001b[39m))\n\u001b[0;32m     54\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(X_test), \u001b[39m4\u001b[39m))\n\u001b[1;32m---> 55\u001b[0m \u001b[39mfor\u001b[39;00m fold, (train_index, valid_index) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(gkf\u001b[39m.\u001b[39msplit(X_train_, y_train_, groups\u001b[39m=\u001b[39mX_train[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[0;32m     56\u001b[0m     X_tr \u001b[39m=\u001b[39m X_train_[train_index]\n\u001b[0;32m     57\u001b[0m     y_tr \u001b[39m=\u001b[39m y_train_\u001b[39m.\u001b[39miloc[train_index]\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:342\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    343\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [960, 960, 1200]"
     ]
    }
   ],
   "source": [
    "#変更後のプログラム \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold # RepeatedStratifiedKFoldを使用する \n",
    "from lightgbm import LGBMClassifier \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix \n",
    " \n",
    " # データの読み込み \n",
    "train = pd.read_csv(\"./original/train.csv\") \n",
    "test = pd.read_csv(\"./original/test.csv\") \n",
    " \n",
    " # 特徴量と目的変数に分ける \n",
    "X_train = train.drop(\"price_range\", axis=1) \n",
    "y_train = train[\"price_range\"] \n",
    "X_test = test.copy() \n",
    " \n",
    " # train_test_splitを使用して学習データを分割する \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) \n",
    " \n",
    " # 特徴量のスケーリング \n",
    "scaler = StandardScaler() \n",
    "X_train_ = scaler.fit_transform(X_train_) \n",
    "X_test = scaler.transform(X_test) \n",
    " \n",
    " # ハイパーパラメータの設定 \n",
    "params = { \n",
    "    'objective': 'multiclass', \n",
    "    'num_class': 4, \n",
    "    'metric': 'multi_error', \n",
    "    'boosting_type': 'gbdt', \n",
    "    'n_jobs': -1, \n",
    "    'num_leaves': 31, \n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': -1, \n",
    "    'min_child_samples': 20, \n",
    "    'subsample_freq': 1, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.6, \n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 0.1, \n",
    "    'verbosity': -1, \n",
    "    'seed': 42 \n",
    "} \n",
    " # GroupKFoldを使用して分割するように変更する\n",
    "from sklearn.model_selection import GroupKFold\n",
    " # 各データのグループを設定する（今回はid）\n",
    "groups = train[\"id\"].values\n",
    " # GroupKFoldを使用してデータを分割するように変更\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "oof = np.zeros((len(X_train_), 4))\n",
    "y_pred = np.zeros((len(X_test), 4))\n",
    "for fold, (train_index, valid_index) in enumerate(gkf.split(X_train_, y_train_, groups=X_train[\"id\"])):\n",
    "    X_tr = X_train_[train_index]\n",
    "    y_tr = y_train_.iloc[train_index]\n",
    "    X_val = X_train_[valid_index]\n",
    "    y_val = y_train_.iloc[valid_index]\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    oof[valid_index] = model.predict_proba(X_val)\n",
    "    y_pred += model.predict_proba(X_test) / n_splits\n",
    " # モデルの評価\n",
    "y_train_pred = model.predict(X_train_)\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Training Accuracy: \", accuracy_score(y_train_, y_train_pred))\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    " # 予測結果の出力\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"price_range\": y_pred})\n",
    "output.to_csv(\"./submission/submission_lgbm_v7.csv\", index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [960, 960, 1200]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m oof \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(X_train_), \u001b[39m4\u001b[39m))\n\u001b[0;32m     43\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(X_test), \u001b[39m4\u001b[39m))\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfor\u001b[39;00m fold, (train_index, valid_index) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(group_kfold\u001b[39m.\u001b[39msplit(X_train_, y_train_, groups\u001b[39m=\u001b[39mX_train[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[0;32m     46\u001b[0m     X_tr \u001b[39m=\u001b[39m X_train_\u001b[39m.\u001b[39miloc[train_index]\n\u001b[0;32m     47\u001b[0m     y_tr \u001b[39m=\u001b[39m y_train_\u001b[39m.\u001b[39miloc[train_index]\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:342\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    343\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mg:\\Data_Analysis_Training\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [960, 960, 1200]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    " # データの読み込み\n",
    "train = pd.read_csv(\"./original/train.csv\")\n",
    "test = pd.read_csv(\"./original/test.csv\")\n",
    " # 特徴量と目的変数に分ける\n",
    "X_train = train.drop(\"price_range\", axis=1)\n",
    "y_train = train[\"price_range\"]\n",
    "X_test = test.copy()\n",
    " # train_test_splitを使用して学習データを分割する\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    " # 特徴量のスケーリング\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train_)\n",
    "X_test = scaler.transform(X_test)\n",
    " # ハイパーパラメータの設定\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'metric': 'multi_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_jobs': -1,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    " # モデルの作成と学習\n",
    "n_splits = 5\n",
    "group_kfold = GroupKFold(n_splits=n_splits)\n",
    "oof = np.zeros((len(X_train_), 4))\n",
    "y_pred = np.zeros((len(X_test), 4))\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(group_kfold.split(X_train_, y_train_, groups=X_train['id'])):\n",
    "    X_tr = X_train_.iloc[train_index]\n",
    "    y_tr = y_train_.iloc[train_index]\n",
    "    X_val = X_train_.iloc[valid_index]\n",
    "    y_val = y_train_.iloc[valid_index]\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    oof[valid_index] = model.predict_proba(X_val)\n",
    "    y_pred += model.predict_proba(X_test) / n_splits\n",
    " # モデルの評価\n",
    "y_train_pred = model.predict(X_train_)\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Training Accuracy: \", accuracy_score(y_train_, y_train_pred))\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    " # 予測結果の出力\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"price_range\": y_pred})\n",
    "output.to_csv(\"./submission/submission_lgbm_v7.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
